{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_movie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "\n",
        "## Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Pyspark"
      ],
      "metadata": {
        "id": "AP4WwTmWRjhT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5bb0d3-eb4f-447b-90e0-302f681ff251"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=49654121086100d533d9661f10289604850528cbc6266f56f563dc8f22eb77a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155202 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUjUvXe3Sjk"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the filea we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRElWs_x2mGh"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "source": [
        "id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.training')\n",
        "\n",
        "id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.test')\n",
        "\n",
        "id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.item')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "Next, we import some of the common libraries needed for our task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3sAVeK1EDZ"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqovskkH1DmC"
      },
      "source": [
        "You can easily check the current version and get the link of the web interface. In the Spark UI, you can monitor the progress of your job and debug the performance bottlenecks (if your Colab is running with a **local runtime**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DueQggJc1DDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "c0370683-036a-40e6-c765-8887143cb7b0"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7526dae5d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://488eccf15ece:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iid7lXcG1CY8"
      },
      "source": [
        "If you are running this Colab on the Google hosted runtime, the cell below will create a *ngrok* tunnel which will allow you to still check the Spark UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n",
        "\n",
        "We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "source": [
        "schema_ratings = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), False),\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"rating\", IntegerType(), False),\n",
        "    StructField(\"timestamp\", IntegerType(), False)])\n",
        "\n",
        "schema_items = StructType([\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"movie\", StringType(), False)])\n",
        "\n",
        "training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n",
        "test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n",
        "items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_m1oygCoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d045c46a-7919-4982-aeaa-6325d3e7af71"
      },
      "source": [
        "training.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Vgo4ovCqtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2422c1-3532-4b63-c02f-051e21e7257e"
      },
      "source": [
        "items.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- movie: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9w2aUvJ7KN"
      },
      "source": [
        "Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "tr_n= training.select(training[\"rating\"]).count()\n",
        "print(\"Training Count\", tr_n)\n",
        "#test\n",
        "ts_n= test.select(test['rating']).count()\n",
        "print(\"test count\", ts_n)"
      ],
      "metadata": {
        "id": "XFSTZ1sMljmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47995558-9360-461e-87fe-df9ba7b3be61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Count 80000\n",
            "test count 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsaYOqRxar2"
      },
      "source": [
        "Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)\n",
        "\n",
        "maxIter = 5, regParam=0.01"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS"
      ],
      "metadata": {
        "id": "RsO6prE_XTbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oitav_xhQD9w"
      },
      "source": [
        "als= ALS(maxIter=5, regParam=0.01, userCol= 'user_id', itemCol='item_id', ratingCol= 'rating', coldStartStrategy='drop')\n",
        "model= als.fit(training)\n",
        "predict= model.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict.show()"
      ],
      "metadata": {
        "id": "oHssUbiblla6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bcc0de-51ba-41af-9c91-a57db130b7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+---------+----------+\n",
            "|user_id|item_id|rating|timestamp|prediction|\n",
            "+-------+-------+------+---------+----------+\n",
            "|    148|      1|     4|877019411| 4.1824536|\n",
            "|    148|      7|     5|877017054| 4.1388817|\n",
            "|    148|     70|     5|877021271|0.46862817|\n",
            "|    148|     71|     5|877019251| 2.8146887|\n",
            "|    148|     78|     1|877399018| 2.5061257|\n",
            "|    148|     98|     3|877017714| 4.8495936|\n",
            "|    148|    114|     5|877016735| 3.0446277|\n",
            "|    148|    116|     5|877398648|-0.5782753|\n",
            "|    148|    140|     1|877019882| 2.9579701|\n",
            "|    148|    163|     4|877021402| 3.8615117|\n",
            "|    148|    169|     5|877020297| 3.9293299|\n",
            "|    148|    172|     5|877016513| 5.6955647|\n",
            "|    148|    177|     2|877020715|  6.429349|\n",
            "|    148|    185|     1|877398385|  5.927431|\n",
            "|    148|    204|     3|877016912| 3.6045551|\n",
            "|    148|    214|     5|877019882| 3.2601361|\n",
            "|    148|    228|     4|877016514| 4.6114254|\n",
            "|    148|    357|     5|877016735| 3.1947732|\n",
            "|    148|    408|     5|877399018| 0.6207267|\n",
            "|    148|    473|     5|877399322| 2.4742966|\n",
            "+-------+-------+------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR1xRvonxiO"
      },
      "source": [
        "Now compute the RMSE on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "eval= RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
        "rmse= eval.evaluate(predict)\n",
        "print(\"Root Mean Square Error\", rmse)\n"
      ],
      "metadata": {
        "id": "ToiJY_UOlmo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f55e75-fc5d-4a1c-d621-2bedba699350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Square Error 1.1295064739701401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBvSaWGEMHXI"
      },
      "source": [
        "At this point, you can use the trained model to produce the top-K recommendations for each user.  Recommend the top three movies for each user. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations= model.recommendForAllUsers(3)\n"
      ],
      "metadata": {
        "id": "MgtQrNJ4lp6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b889abbf-2755-4067-b22b-ad5adffd001b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations.select('user_id', 'recommendations.item_id', 'recommendations.rating').show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hhoRG8Uoeab",
        "outputId": "1f51cffb-f7d3-4d6c-aa87-ee2367f832bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------------------+\n",
            "|user_id|           item_id|              rating|\n",
            "+-------+------------------+--------------------+\n",
            "|      1| [1643, 1368, 320]|[6.9078393, 6.706...|\n",
            "|      3| [1268, 854, 1065]|[7.8648257, 7.800...|\n",
            "|      5|  [968, 1077, 601]|[7.4901333, 7.456...|\n",
            "|      6|  [1137, 919, 906]|[6.2349424, 5.650...|\n",
            "|      9| [1059, 1483, 916]|[11.311695, 11.25...|\n",
            "|     12| [962, 1065, 1394]|[9.937338, 8.5124...|\n",
            "|     13|[1184, 1473, 1643]|[6.290877, 6.2048...|\n",
            "|     15|[1137, 1159, 1540]|[7.2059, 7.177743...|\n",
            "|     16| [965, 1643, 1589]|[8.001853, 7.9140...|\n",
            "|     17|  [1160, 253, 865]|[10.695154, 10.25...|\n",
            "|     19|[1268, 1205, 1172]|[10.449025, 10.22...|\n",
            "|     20|  [916, 1615, 774]|[12.800352, 10.97...|\n",
            "|     22|  [253, 583, 1643]|[8.234476, 8.0419...|\n",
            "|     26| [1643, 793, 1195]|[5.546549, 5.1324...|\n",
            "|     27|  [253, 1319, 583]|[13.237639, 11.83...|\n",
            "|     28|[1059, 1643, 1131]|[6.588251, 6.3342...|\n",
            "|     31| [955, 1643, 1240]|[7.801644, 7.3746...|\n",
            "|     34| [1368, 695, 1154]|[12.939422, 11.99...|\n",
            "|     35|  [962, 834, 1631]|[7.8735175, 6.832...|\n",
            "|     37| [1063, 253, 1203]|[7.0392466, 6.690...|\n",
            "+-------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAOmc6JHaDmj"
      },
      "source": [
        "Print the name of the movies recommended for user 444  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_id= recommendations.where(recommendations.user_id==444).select('recommendations.item_id').collect()\n",
        "items.filter(items.item_id == movie_id[0][0][1])\n",
        "for i in range(3):  # 3--> number of recommended movies\n",
        "  print('Movie', i+1)\n",
        "  items.filter(items.item_id == movie_id[0][0][i]).show()\n"
      ],
      "metadata": {
        "id": "R2c_n9MnROY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73bee69-414c-4e87-c31c-09f0b6542199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie 1\n",
            "+-------+--------------------+\n",
            "|item_id|               movie|\n",
            "+-------+--------------------+\n",
            "|   1160|Love! Valour! Com...|\n",
            "+-------+--------------------+\n",
            "\n",
            "Movie 2\n",
            "+-------+--------------------+\n",
            "|item_id|               movie|\n",
            "+-------+--------------------+\n",
            "|    989|Cats Don't Dance ...|\n",
            "+-------+--------------------+\n",
            "\n",
            "Movie 3\n",
            "+-------+--------------------+\n",
            "|item_id|               movie|\n",
            "+-------+--------------------+\n",
            "|    253|Pillow Book, The ...|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Collaborative Filtering"
      ],
      "metadata": {
        "id": "_YRZQ0Txt1pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install surprise to build recommender in python\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgBu6Sp78OVi",
        "outputId": "9109dd07-e366-4100-8a4e-87ba497aa81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1630168 sha256=e9c30666b06241dd77de8afa17f32a2e3314ac0f0c28bfe4c78d94311765385e\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task. Memory-based Filtering \n",
        "\n",
        "Your task is to train a predictor using the `training` set provided above, and make predictions on the `test` set."
      ],
      "metadata": {
        "id": "m1WKy3DJst2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. User-based recommendation\n",
        "\n",
        "To make a prediction on user $u$'s rating on item $i$ ($R_{u, i}$), User-based recommendation finds the top-N user neighbors who have already completed rating on $i$, taking their average (unweighted or weighted by their similarity with $u$) as the prediction $\\hat{R}_{u,i}$.\n"
      ],
      "metadata": {
        "id": "xwDY23pa-fBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1). Use default parameters, report *RMSE* on training & test set, respectively."
      ],
      "metadata": {
        "id": "rZlEfdJlY3b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import KNNWithMeans\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n"
      ],
      "metadata": {
        "id": "TXbygNacOZmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#convert pyspark dataframe to pandas dataframe\n",
        "training_df, testing_df = train_test_split(training.toPandas(), test_size=0.25)\n",
        "test_df= test.toPandas()\n",
        "\n",
        "#creating data\n",
        "reader= Reader(rating_scale=(0,5))\n",
        "training_data = Dataset.load_from_df(training_df[['user_id','item_id','rating']], reader)\n",
        "testing_data= Dataset.load_from_df(testing_df[['user_id','item_id','rating']], reader)\n",
        "test_data= Dataset.load_from_df(test_df[['user_id','item_id','rating']], reader)\n",
        "\n",
        "#generating raw data frame\n",
        "tr= Dataset.construct_trainset(training_data, [(uid, iid, r, None) for (uid, iid, r) in zip(training_df['user_id'], training_df['item_id'], training_df['rating'])])\n",
        "ts= Dataset.construct_testset(testing_data, [(uid, iid, r, None) for (uid, iid, r) in zip(testing_df['user_id'], testing_df['item_id'], testing_df['rating'])])\n",
        "testset= Dataset.construct_testset(test_data, [(uid, iid, r, None) for (uid, iid, r) in zip(test_df['user_id'], test_df['item_id'], test_df['rating'])])"
      ],
      "metadata": {
        "id": "TQEjFhnBlftr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train - train\n",
        "predictions_tr_user= KNNWithMeans().fit(tr).test(ts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EFQrbSw8zKI",
        "outputId": "7c1bf8dd-5012-48c6-ab4a-8755add5f9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate RMSE of the actual ratings $R$ and the predicted ratings $\\hat{R}$ in the training set."
      ],
      "metadata": {
        "id": "cSbkzmEDbfAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rmse train set\n",
        "from surprise.accuracy import rmse\n",
        "print(\"RMSE On Train\", rmse(predictions_tr_user))"
      ],
      "metadata": {
        "id": "HrupefNdl6-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3a2656-3488-4e5e-d2f2-202268c3fcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9676\n",
            "RMSE On Train 0.9675561391297695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make predictions on the test set"
      ],
      "metadata": {
        "id": "1fXgs11lWCcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df1= training.toPandas()\n",
        "training_data1 = Dataset.load_from_df(training_df1[['user_id','item_id','rating']], reader)\n",
        "trainset= Dataset.construct_trainset(training_data1, [(uid, iid, r, None) for (uid, iid, r) in zip(training_df1['user_id'], training_df1['item_id'], training_df1['rating'])])\n",
        "\n",
        "#testset\n",
        "predictions_ts_user= KNNWithMeans().fit(trainset).test(testset)"
      ],
      "metadata": {
        "id": "zXS1ykHHnF5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84227673-c110-4c47-c4af-8f3a64398bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate RMSE of the actual ratings $R$ and the predicted ratings $\\hat{R}$ from the trained user-based recommendation."
      ],
      "metadata": {
        "id": "D9qPJXotW1Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rmse test set\n",
        "print(\"RMSE On Test Data\", rmse(predictions_ts_user))"
      ],
      "metadata": {
        "id": "GApihBisSvII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2ebfec-dc2c-410f-9e65-844d6cec0371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9663\n",
            "RMSE On Test Data 0.9663023895782573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2). Now display the top 10 movies for user 10, ranked by the predicted rating scores in the test set."
      ],
      "metadata": {
        "id": "Twu6IIH6chLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(items.toPandas())"
      ],
      "metadata": {
        "id": "uE4zu0Rici1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d305b21-99d5-4587-e26d-ffe1e3b494af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame(predictions_ts_user)\n",
        "\n",
        "for i in range(1,11):\n",
        "  df = temp[temp.uid == i].sort_values('est')[:10]\n",
        "  print(\" For user\", i)\n",
        "  for iid in df.iid:\n",
        "    movie= items[items.item_id == iid].collect()\n",
        "    print(movie[0][1], end= \",\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPNFqkpp13GD",
        "outputId": "b59edd05-6fe7-4912-8c40-6c6cb1f49f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " For user 1\n",
            "Mad Love (1995),Striptease (1996),Jungle2Jungle (1997),All Dogs Go to Heaven 2 (1996),Free Willy (1993),Theodore Rex (1995),Flipper (1996),Kansas City (1996),Batman & Robin (1997),Kull the Conqueror (1997),\n",
            "\n",
            " For user 2\n",
            "3 Ninjas: High Noon At Mega Mountain (1998),In & Out (1997),Up Close and Personal (1996),Hoodlum (1997),Fierce Creatures (1997),Midnight in the Garden of Good and Evil (1997),River Wild, The (1994),Once Upon a Time... When We Were Colored (1995),FairyTale: A True Story (1997),Mighty Aphrodite (1995),\n",
            "\n",
            " For user 3\n",
            "Hoodlum (1997),Critical Care (1997),Mimic (1997),Dante's Peak (1997),Prophecy II, The (1998),Hard Rain (1998),How to Be a Player (1997),Alien: Resurrection (1997),Liar Liar (1997),Fallen (1998),\n",
            "\n",
            " For user 4\n",
            "Event Horizon (1997),Liar Liar (1997),Mimic (1997),Client, The (1994),Scream (1996),Wedding Singer, The (1998),Ulee's Gold (1997),Incognito (1997),Star Wars (1977),One Flew Over the Cuckoo's Nest (1975),\n",
            "\n",
            " For user 5\n",
            "Children of the Corn: The Gathering (1996),Amityville: A New Generation (1993),Free Willy 3: The Rescue (1997),Jungle2Jungle (1997),Jaws 3-D (1983),Beverly Hills Cop III (1994),Spy Hard (1996),Operation Dumbo Drop (1995),Heavyweights (1994),Black Sheep (1996),\n",
            "\n",
            " For user 6\n",
            "First Wives Club, The (1996),Liar Liar (1997),Tin Cup (1996),Rock, The (1996),Nixon (1995),In & Out (1997),Matilda (1996),Phenomenon (1996),Red Rock West (1992),People vs. Larry Flynt, The (1996),\n",
            "\n",
            " For user 7\n",
            "White Man's Burden (1995),Body Parts (1991),Tales from the Hood (1995),NeverEnding Story III, The (1994),Audrey Rose (1977),Pocahontas (1995),Star Trek V: The Final Frontier (1989),Rocket Man (1997),Event Horizon (1997),George of the Jungle (1997),\n",
            "\n",
            " For user 8\n",
            "Free Willy 3: The Rescue (1997),McHale's Navy (1997),Bean (1997),Jackal, The (1997),Die Hard: With a Vengeance (1995),Liar Liar (1997),True Lies (1994),Contact (1997),Executive Decision (1996),Full Metal Jacket (1987),\n",
            "\n",
            " For user 9\n",
            "English Patient, The (1996),Dark City (1998),Face/Off (1997),Streetcar Named Desire, A (1951),Boogie Nights (1997),Deer Hunter, The (1978),Gandhi (1982),Shanghai Triad (Yao a yao yao dao waipo qiao) (1995),Roman Holiday (1953),Vertigo (1958),\n",
            "\n",
            " For user 10\n",
            "Bad Moon (1996),Dirty Dancing (1987),Substance of Fire, The (1996),Evita (1996),House of the Spirits, The (1993),Barcelona (1994),Tin Men (1987),City Hall (1996),Mother (1996),Kicking and Screaming (1995),\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3). From what we learned in class, the number of nearest neighbors ($k$) considered for rating estimation $\\hat{R}$ is an important hyperparameter affecting the prediction results. Repeat the training procedure above with different nearest neighbor selections (2-10), find the optimal $k$ in your experiment and report the corresponding *RMSE* in the test set."
      ],
      "metadata": {
        "id": "pgcPKKcCjxxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_k=[]\n",
        "for i in range(2,11):\n",
        "  predictions= KNNWithMeans(k=i).fit(tr).test(testset)   \n",
        "  rmse_k.append((i,rmse(predictions)))"
      ],
      "metadata": {
        "id": "nn1RcxX6mIbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b171b1-1bf6-406e-b9cd-ebf11364a387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.1426\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0916\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0638\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0450\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0334\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0239\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0164\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0108\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_kvalue= sorted(rmse_k, key= lambda x: x[1])[0][0]\n",
        "print(\"Optimal K value\", best_kvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftQ9iOejF-7C",
        "outputId": "902bc603-354a-486b-bb22-65621a7f33bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal K value 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we can write a for-loop to iterate throuogh different choices, but scikit-surprise provides us with a simplified cross-validation interface (`surprise.model_selection.GridSearchCV`) to fine-tune such hyperparameter.\n",
        "\n",
        "\n",
        "Report the optimal k value. \n",
        "\n",
        "Report the RMSE given the optimal k value"
      ],
      "metadata": {
        "id": "M8VS4LnKn6zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "5QMlaQ_dpRbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params= {\"k\":[2,3,4,5,6,7,8,9,10] }\n",
        "grid= GridSearchCV(KNNWithMeans, param_grid= params, measures=['rmse'])\n",
        "grid.fit(training_data1)"
      ],
      "metadata": {
        "id": "0czvPuA0mPOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8e5d11-362a-4068-c8d4-24b13e9568e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Value of K:{} and corresponding RMSE Value is {}\".format(grid.best_params['rmse']['k'], grid.best_score['rmse']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "257pdOE_RAbR",
        "outputId": "f1f0a158-efe0-46dd-ec08-d2caa89ebf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Value of K:10 and corresponding RMSE Value is 0.9808492031739593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. **item-based recommendation**\n",
        "\n",
        "To make a prediction on user $u$'s rating on item $i$ ($R_{u, i}$), Item-based recommendation finds the top-N item neighbors (the user has rated) to $i$, taking their average (unweighted or weighted by their similarity with $i$) as the prediction $\\hat{R}_{u,i}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "x6kjzFPPqwso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1). Similar to the previous question, implement the item-based recommender systems trained on the  `training` set, report the *RMSE* on both the `training` and `test` set. (Note: apply the optimal $k$ obtained in last question.)"
      ],
      "metadata": {
        "id": "yn2cUNQ_swP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train set\n",
        "sim_options= {'user_based': False }\n",
        "predictions_tr_item= KNNWithMeans( sim_options=sim_options).fit(tr).test(ts)\n",
        "print(\"RMSE On Train\", rmse(predictions_tr_item))"
      ],
      "metadata": {
        "id": "bnPbOaHGmTTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08145d3-b6bd-479b-c9c6-aee0bd718477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9521\n",
            "RMSE On Train 0.9520802458970272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "predictions_ts_item= KNNWithMeans(sim_options=sim_options).fit(tr).test(testset)\n",
        "print(\"RMSE On Train\", rmse(predictions_ts_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFx4UHOKU2YB",
        "outputId": "6b4525f5-3b18-4899-f263-965affd72011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9648\n",
            "RMSE On Train 0.9648360997055023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2). Similar to previous question, display the top 10 movies for user 10, ranked by the predicted rating scores in the test set."
      ],
      "metadata": {
        "id": "7fjjupuctTLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "temp = pd.DataFrame(predictions_ts_item)\n",
        "\n",
        "for i in range(1,11):\n",
        "  df = temp[temp.uid == i].sort_values('est')[:10]\n",
        "  print(\" For user\", i)\n",
        "  for iid in df.iid:\n",
        "    movie= items[items.item_id == iid].collect()\n",
        "    print(movie[0][1], end= \",\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "Uzzs5B9StSse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6214a4fa-e692-4ef6-944a-0d28b385fc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " For user 1\n",
            "Kansas City (1996),Theodore Rex (1995),Striptease (1996),Jungle2Jungle (1997),All Dogs Go to Heaven 2 (1996),Event Horizon (1997),Lawnmower Man, The (1992),Mad Love (1995),Flipper (1996),Hot Shots! Part Deux (1993),\n",
            "\n",
            " For user 2\n",
            "3 Ninjas: High Noon At Mega Mountain (1998),Fierce Creatures (1997),River Wild, The (1994),Hoodlum (1997),Up Close and Personal (1996),FairyTale: A True Story (1997),In & Out (1997),Midnight in the Garden of Good and Evil (1997),Mighty Aphrodite (1995),Once Upon a Time... When We Were Colored (1995),\n",
            "\n",
            " For user 3\n",
            "Mimic (1997),House of Yes, The (1997),187 (1997),Dante's Peak (1997),Devil's Own, The (1997),Critical Care (1997),Hard Rain (1998),Prophecy II, The (1998),Hoodlum (1997),Alien: Resurrection (1997),\n",
            "\n",
            " For user 4\n",
            "Mimic (1997),Event Horizon (1997),Incognito (1997),Liar Liar (1997),Scream (1996),Wedding Singer, The (1998),Client, The (1994),Ulee's Gold (1997),Star Wars (1977),One Flew Over the Cuckoo's Nest (1975),\n",
            "\n",
            " For user 5\n",
            "Amityville: A New Generation (1993),Children of the Corn: The Gathering (1996),Heavyweights (1994),Spy Hard (1996),Free Willy 3: The Rescue (1997),Sudden Death (1995),Beverly Hills Cop III (1994),Operation Dumbo Drop (1995),Jaws 3-D (1983),Striking Distance (1993),\n",
            "\n",
            " For user 6\n",
            "Liar Liar (1997),Nixon (1995),Tin Cup (1996),Traveller (1997),First Wives Club, The (1996),Matilda (1996),Kama Sutra: A Tale of Love (1996),In & Out (1997),Courage Under Fire (1996),Phenomenon (1996),\n",
            "\n",
            " For user 7\n",
            "Body Parts (1991),So Dear to My Heart (1949),Audrey Rose (1977),NeverEnding Story III, The (1994),Tales from the Hood (1995),White Man's Burden (1995),Star Trek V: The Final Frontier (1989),Pocahontas (1995),Stephen King's The Langoliers (1995),Rocket Man (1997),\n",
            "\n",
            " For user 8\n",
            "Free Willy 3: The Rescue (1997),McHale's Navy (1997),Bean (1997),Jackal, The (1997),Liar Liar (1997),Die Hard: With a Vengeance (1995),In & Out (1997),Executive Decision (1996),True Lies (1994),Full Metal Jacket (1987),\n",
            "\n",
            " For user 9\n",
            "English Patient, The (1996),Boogie Nights (1997),Shanghai Triad (Yao a yao yao dao waipo qiao) (1995),Face/Off (1997),Streetcar Named Desire, A (1951),Dark City (1998),Deer Hunter, The (1978),Gandhi (1982),Vertigo (1958),Roman Holiday (1953),\n",
            "\n",
            " For user 10\n",
            "Bad Moon (1996),Browning Version, The (1994),Barcelona (1994),House of the Spirits, The (1993),Tin Men (1987),City Hall (1996),Evita (1996),Bridges of Madison County, The (1995),Substance of Fire, The (1996),Dirty Dancing (1987),\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3). Given the same number of nearest neighbor ($k$), compare and discuss the user-based and item-based recommendation, which performs better on the test set?"
      ],
      "metadata": {
        "id": "-jQAsg8Ftczx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the testset: \n",
        "User-Based works better than Item-Based. \n",
        "\n",
        "User Based Recommendation is user centric and suffer from high variance and low bias due to sensitivity towards recorded interactions and as interactions are based on user's similarity. \n",
        "\n",
        "Item Based Recommendation is intem centric, and suffer from low variance, and high bias. \n"
      ],
      "metadata": {
        "id": "XL1UrNL-bwo4"
      }
    }
  ]
}